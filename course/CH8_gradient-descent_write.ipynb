{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8: Optimization & Gradient Descent\n",
    "\n",
    "**Jonny Yu, March 2024**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture Learning Objectives\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explain the difference between a model, loss function, and optimization algorithm in the context of machine learning\n",
    "- Explain how the gradient descent algorithm works\n",
    "- Apply gradient descent to linear and logistic regression\n",
    "- Use `scipy.optimize.minimize()` to minimize a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from utils.plotting import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Optimization and Machine Learning\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In data science, we optimize a lot of stuff, e.g., in linear regression we optimize for the intercept and coefficients, in clustering we optimize clusters, in neural networks we optimize the weights in our network (more on that in a later lecture), etc.\n",
    "- In one sentence: optimization simply refers to minimizing/maximizing a function, e.g.:\n",
    "    - What value of $x$ minimizes the function $f(x) = (x-2)^2 + 5$? What is the minimum value?\n",
    "    - *Answers*: $x=2$, and $f(x)=5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can start to think of ML as a 3-step process:\n",
    "    1. **Choose your model**: controls the space of possible functions that map $X$ to $y$ (e.g., a linear model can only learn linear functions)\n",
    "    2. **Choose your loss function**: tells us how to compare these various functions (e.g., is $y=5 + 2x_1+3x_2$ a better model than $y=1 + 10x_1-x_2$?)\n",
    "    3. **Choose your optimization algorithm**: finds the minimum of the loss function (e.g., what is the optimum value of $w_0$ and $w_1$ in $y=w_0 + w_1x$?)\n",
    "- In this lecture we'll be taking a visual approach to understanding optimization and gradient descent (an optimization algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loss Functions\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A loss function is what we use to map the performance of our model to a real number and it's the thing we want to optimize!\n",
    "- For example, here's the mean squared error (a common loss function):\n",
    "\n",
    "$$f(y,\\hat{y})=\\frac{1}{n}\\sum^{n}_{i=1}(\\hat{y_i}-y_i)^2$$\n",
    "\n",
    "- Where $y_i$ is the actual response and $\\hat{y_i}$ is the predicted response\n",
    "- Consider a simple linear regression model $\\hat{y_i} = w_0 + w_1x_i$, then our loss function is:\n",
    "\n",
    "$$f(y,x,w)=\\frac{1}{n}\\sum^{n}_{i=1}((w_0 + w_1x_i)-y_i))^2$$\n",
    "\n",
    "- The optimization problem here is to find the values of $w_0$ and $w_1$ that minimizes the MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimizing Linear Regression\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I'm going to build up the intuition for optimization in a practical and visual way with the help of our old friend linear regression\n",
    "- If you'd prefer a more mathematical approach I encourage you to check out Mike's lecture on Youtube [Thinking about Optimization](https://www.youtube.com/watch?v=bzj1L997uT8&feature=youtu.be&t=67) or [Chapter 7 of Mathematics for Machine Learning, by Deisenroth et al.](https://mml-book.github.io/book/mml-book.pdf)\n",
    "- We'll use a dataset of [Pokemon](https://www.pokemon.com/us/) \"attack\" and \"defense\" stats to do this, I'm going to start with just 10 observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Throughout this lecture, I'm leveraging plotting scripts I imported from `utils.plotting`. I abstracted the code out of the notebook to avoid cluttering the lecture notes and how I made these plots is not important, but feel free to check out the source code if you wish!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">ps. the most powerful pokemon of them all, **Poketom**, is unfortunately not in this dataset:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recall simple linear regression: $\\hat{y_i} = w_0 + w_1x_i$ (where  $w_0$ is the intercept and $w_1$ is the slope coefficient)\n",
    "- If we assume ($w_0$, $w_1$) = (10, 0.5) we would have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's plot that result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The fit is not very good... We need to optimize it!\n",
    "- A **loss function** quantifies the fit of our model and we want to find the parameters of our model that minimize the loss function\n",
    "- We'll use mean-squared-error (MSE) as our loss function:\n",
    "\n",
    "$$f(w)=\\frac{1}{n}\\sum^{n}_{i=1}((w_0 + w_1x_i)-y_i))^2$$\n",
    "\n",
    "- Where $n$ is the number of data points we have (10 in our case).\n",
    "- We'll use the sklearn function `mean_squared_error()` which I imported at the top of the notebook to calculate MSE for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So this is the mean error of every single training example\n",
    "- For now, let's assume the intercept is 0 ($w_0 = 0$) and **just focus on optimizing the slope** ($w_1$)\n",
    "- One thing we could do is try many different values for the slope and find the one that minimizes the MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It looks like a slope of 0.9 gives us the lowest MSE (~184.4)\n",
    "- But you can imagine that this \"grid search\" approach quickly becomes computationally intractable as the size of our data set and number of model parameters increases!\n",
    "- So we need a better way to optimize our parameters... we need an optimization algorithm!\n",
    "- The one we'll focus on today is **Gradient Descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gradient Descent With One Parameter\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient descent is an optimization algorithm that can help us optimize our loss function\n",
    "- As the name suggest, we are going to leverage the **gradient** of our loss function to help us optimize our model parameters\n",
    "- The gradient is just a vector of (partial) derivatives of the loss function w.r.t the model parameters\n",
    "- Sounds complicated but it's not at all (as I'll hopefully show you)\n",
    "- In plain English, the gradient will tell us two things:\n",
    "    1. Which direction to move our parameter in to decrease loss (i.e., should we increase or decrease its value?)\n",
    "    2. How far to move it (i.e., should we adjust it by 0.1 or 2 or 50 etc.?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's forget about the intercept now and just work with this simple linear model: $\\hat{y_i}=wx_i$\n",
    "- For our model the loss function has the form:\n",
    "\n",
    "$$f(w)=\\frac{1}{n}\\sum^{n}_{i=1}((wx_i)-y_i))^2$$\n",
    "\n",
    "- The gradient of this function with respect to the parameter $w$ is:\n",
    "\n",
    "$$\\frac{d}{dw}f(w)=\\frac{1}{n}\\sum^{n}_{i=1}2x_i(wx_i - y_i)$$\n",
    "\n",
    "- Let's code that up:\n",
    "- Let's calculate the gradient of our loss function at a slope of $w = 0.5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So this is the average gradient across all training examples and tells us how to adjust $w$ to reduce the MSE loss over all training examples!\n",
    "- Recall from calculus that the **gradient actually points in the direction of steepest ascent** (read more in [Appendix A](appendixA_gradients.ipynb))\n",
    "- We want to move in the direction of steepest descent (the negative of the gradient) to reduce our loss\n",
    "- For example, the above gradient is negative, but we obviously need to **increase** the value of our slope ($w$) to reduce our loss as you can see here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The amount we adjust our slope each iteration is controlled by a \"learning rate\", denoted $\\alpha$ (note the minus in the equation below which accounts for the \"descent\" as discussed above):\n",
    "\n",
    "$$w_{new} = w - \\alpha \\times gradient$$\n",
    "\n",
    "$$w_{new} = w - \\alpha \\frac{d}{dw}f(w)$$\n",
    "\n",
    "- $\\alpha$ is a hyperparameter that can be optimized, typical values range from 0.001 to 0.9\n",
    "- With the math out of the way, we're now ready to use gradient descent to optimize our slope\n",
    "- Typically we stop gradient descent when:\n",
    "    1. the step size is smaller than some threshold; or,\n",
    "    2. a certain number of steps is completed\n",
    "- So the pseudo code for gradient descent boils down to this:\n",
    "\n",
    "```sh\n",
    "1. begin with with some arbitrary w\n",
    "while stopping criteria not met:\n",
    "    2. calculate mean gradient across all examples\n",
    "    3. update w based on gradient and learning rate\n",
    "    4. repeat\n",
    "```\n",
    "\n",
    "- Let's go ahead and implement that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w, alpha, ϵ=2e-4, max_iterations=5000, print_progress=10):\n",
    "\n",
    "\n",
    "gradient_descent(x, y, w=0.5, alpha=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's take a look at the journey our slope parameter went on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradient_descent(x, y, w=0.5, alpha=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see what happens if we increase the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent(x, y, w=0.5, alpha=0.00005, print_progress=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradient_descent(x, y, w=0.5, alpha=0.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's increase a little more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent(x, y, w=0.5, alpha=0.00015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradient_descent(x, y, w=0.5, alpha=0.00015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If our learning rate is too high, we'll overshoot and never converge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent(x, y, w=0.5, alpha=0.00018, max_iterations=4, print_progress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradient_descent(x, y, w=0.5, alpha=0.00018, max_iterations=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cool, we just implemented gradient descent from scratch!\n",
    "- Now let's try optimizing for two parameters, intercept and slope, simultaneously..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gradient Descent With Two Parameters\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And then there were two...\n",
    "\n",
    "\n",
    "- Most of the models you'll be working with will have more than just one parameter to update - neural networks typically have hundreds, thousands, and even millions of parameters!\n",
    "- Let's extend the above workflow to two parameters, the intercept ($w_0$) and the slope ($w_1$)\n",
    "- Just to help you get a visual of what's going on, let's take our \"grid search approach\" and make a plot of it but this time with two parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above is the surface of MSE for different values of `intercept` ($w_0$) and `slope` ($w_1$)\n",
    "- The approach is exactly as before, but we're operating on two parameters now and the gradient of the intercept is a little different to the slope:\n",
    "\n",
    "$$f(w)=\\frac{1}{n}\\sum^{n}_{i=1}((w_0 + w_1x)-y_i))^2$$\n",
    "\n",
    "$$\\frac{\\partial{}}{\\partial{}w_0}f(w)=\\frac{1}{n}\\sum^{n}_{i=1}2((w_0 + w_1x) - y_i)$$\n",
    "\n",
    "$$\\frac{\\partial{}}{\\partial{}w_1}f(w)=\\frac{1}{n}\\sum^{n}_{i=1}2x_i((w_0 + w_1x) - y_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's define a function that returns the gradient (partial derivatives) of the slope and intercept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x, y, w):\n",
    "\n",
    "\n",
    "gradient(x, y, w=[10, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can already see that our the gradient of our slope is orders of magnitude larger than our intercept... we'll look more at this issue shortly\n",
    "- For now let's re-write our gradient descent function\n",
    "- It's almost exactly the same as before, but now we are updating the slope **and** the intercept each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w, alpha, ϵ=2e-4, max_iterations=5000, print_progress=10):\n",
    "    \"\"\"Gradient descent for optimizing simple linear regression.\"\"\"\n",
    "\n",
    "\n",
    "gradient_descent(x, y, w=[10, 0.5], alpha=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hmm... our algorithm worked but our intercept never changed\n",
    "- Let's take a look at what happened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradient_descent_2d(x, y, w=[10, 0.5], m_range=np.arange(0, 2.05, 0.05), b_range=np.arange(-30, 31, 2), alpha=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- That's because the slope gradient is **wayyyyy** bigger than the intercept gradient\n",
    "- Let's see what the real value of these params are using sklearn's implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So we're a bit off here\n",
    "- We need to get the slope and intercept on the same scale..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are a few ways we can solve this problem, but the most common way is to simply scale your features before gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now let's check a random gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Great, they are on a similar scale now, let's retry gradient descent with our scaled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Matches perfectly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once again, changing the learning rate will affect our descent (I added some markers on this plot to show you that we're bouncing back-and-forth):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Other Optimization Algorithms\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When you saw us using gradients earlier on you might have thought, why not just set the derivative to 0 and solve?\n",
    "- You sure could do this! And in general, if a closed form solution exists for your problem, you should typically use it\n",
    "- However:\n",
    "    - Most problems in ML do not have a closed-form solution\n",
    "    - Even if a closed form solution exists (e.g., linear regression), it can be extremely computationally expensive to compute if your dataset is large (many observations and/or many features)\n",
    "- In these cases, optimization algorithms like GD are appropriate choices\n",
    "- In actuality you will almost never use vanilla GD in practice because it's actually very slow (but the intuition behind it forms the basis of tons of optimization algorithms so it's a great place to start learning)\n",
    "- We'll look at a computationally lighter version of GD next lecture (stochastic gradient descent) and there are also many other algorithms available!\n",
    "- You can explore the `scipy` function `minimize` to play around with some of these algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here was our gradient descent implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `minimize` takes as argument the function to minimize, the function's gradient and the starting parameter values\n",
    "- For a linear regression model, the MSE loss and gradient take the general form:\n",
    "\n",
    "$$f(w)=\\frac{1}{n}\\sum^{n}_{i=1}(w^Tx_i-y_i)^2$$\n",
    "\n",
    "$$\\frac{\\partial{}}{\\partial{}f(w)}=\\frac{2}{n}\\sum^{n}_{i=1}(w^Tx_i-y_i)x_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I've coded up that up using matrix multiplication (more on that a bit later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(w, X, y):\n",
    "\n",
    "\n",
    "\n",
    "def mse_grad(w, X, y):\n",
    "    \"\"\"Gradient of mean squared error.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we can call `minimize`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(mse, w, jac=mse_grad, args=(x, y)).x  # these are the weights, it's a bit confusing because they are called \"x\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are plenty of methods you can look into (most give the same answers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in [\"CG\", \"L-BFGS-B\", \"SLSQP\", \"TNC\"]:\n",
    "    print(f\"Method: {method}, Weights: {minimize(mse, w, jac=mse_grad, args=(x, y), method=method).x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Lecture Exercise: Optimizing Logistic Regression\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this section I'm going to demo optimizing a Logistic Regression problem to drive home some of the points we learned in this lecture\n",
    "- I'm going to sample 70 \"legendary\" (which are typically super-powered) and \"non-legendary\" pokemon from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We'll be using the \"trick of ones\" to help us implement these computations efficiently\n",
    "- For example, if we have a simple linear regression model with an intercept and a slope:\n",
    "\n",
    "$$\\hat{y} = \\boldsymbol{w^T}\\boldsymbol{x} = w_0\\times{}1 + w_1\\times{}x$$\n",
    "\n",
    "- Let's represent that in matrix form:\n",
    "\n",
    "$$\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{bmatrix} \\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}$$\n",
    "\n",
    "- Now we can calculate $\\mathbf{y}$ using matrix multiplication and the \"matmul\" Python operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/matmul.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We're going to create a logistic regression model to classify a Pokemon as \"legendary\" or not\n",
    "- Recall that in logistic regression we map our linear model to a probability:\n",
    "\n",
    "$$z=\\boldsymbol{w^T}\\boldsymbol{x}$$\n",
    "\n",
    "$$P(y = 1) = \\frac{1}{(1+\\exp(-z))}$$\n",
    "\n",
    "- For classification purposes, we typically then assign this probability to a discrete class (0 or 1) based on a threshold (0.5 by default):\n",
    "\n",
    "$$y=\\left\\{\n",
    "\\begin{array}{ll}\n",
    "    0, & P(y = 1)\\le0.5 \\\\\n",
    "    1, & P(y = 1)>0.5 \\\\\n",
    "\\end{array} \n",
    "\\right.$$ \n",
    "\n",
    "- Let's code that up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, w, output=\"soft\", threshold=0.5):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For example, if $w = [0, 0]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's calculate the accuracy of the above model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Just like in the linear regression example earlier, we want to optimize the values of our weights!\n",
    "- We need a loss function!\n",
    "- As you discussed in 573, we use the log loss (cross-entropy loss) to optimize logistic regression\n",
    "- Here's the loss function and its gradient (see [Appendix B](appendixB_logistic-loss.ipynb) if you want to learn more about these, they're actually quite simple!):\n",
    "  \n",
    "$$f(w)=-\\frac{1}{n}\\sum_{i=1}^ny_i\\log\\left(\\frac{1}{1 + \\exp(-w^Tx_i)}\\right) + (1 - y_i)\\log\\left(1 - \\frac{1}{1 + \\exp(-w^Tx_i)}\\right)$$\n",
    "\n",
    "$$\\frac{\\partial f(w)}{\\partial w}=\\frac{1}{n}\\sum_{i=1}^nx_i\\left(\\frac{1}{1 + \\exp(-w^Tx_i)} - y_i\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss(w, X, y):\n",
    "\n",
    "\n",
    "\n",
    "def logistic_loss_grad(w, X, y):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_opt = minimize(logistic_loss, np.array([-1, 1]), jac=logistic_loss_grad, args=(X, y)).x\n",
    "w_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's check our solution against the `sklearn` implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is what the optimized model looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking that against our sklearn model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(x.reshape(-1, 1), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I mean, that's so cool team! We replicated the sklearn behavour from scratch!!!!\n",
    "- In Lab 1 you'll actually write your own logistic regression class from scratch (including `.fit()`, `.predict()`, `.predict_proba()`, and `.score()`)\n",
    "- By the way, I've been doing things in 2D here because it's easy to visualize, but let's double check that we can work in more dimensions by using `attack`, `defense` and `speed` to classify a Pokemon as `legendary` or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looks good to me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. The Lecture in Three Conjectures\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loss functions and optimization algorithms are different things\n",
    "    - Loss functions map the performance of your model to a number\n",
    "    - Optimization algorithms find the model parameters that minimize the loss function\n",
    "2. Gradient descent is an optimization algorithm, you can find others in `scipy.optimize.minimize()`\n",
    "3. Gradient is simple to code up but not very efficient (it uses all the data to update weights each iteration), we'll explore a computationally cheaper method of gradient descent next lecture (stochastic gradient descent)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
